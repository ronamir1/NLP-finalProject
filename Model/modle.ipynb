{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls -la .","metadata":{"execution":{"iopub.status.busy":"2021-06-23T10:59:16.28759Z","iopub.execute_input":"2021-06-23T10:59:16.288022Z","iopub.status.idle":"2021-06-23T10:59:16.938496Z","shell.execute_reply.started":"2021-06-23T10:59:16.287926Z","shell.execute_reply":"2021-06-23T10:59:16.937443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/output'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T11:13:23.689332Z","iopub.execute_input":"2021-06-12T11:13:23.689685Z","iopub.status.idle":"2021-06-12T11:13:23.695189Z","shell.execute_reply.started":"2021-06-12T11:13:23.689648Z","shell.execute_reply":"2021-06-12T11:13:23.693962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/OnlpLab/Hebrew-Sentiment-Data.git","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:13:23.697545Z","iopub.execute_input":"2021-06-12T11:13:23.698145Z","iopub.status.idle":"2021-06-12T11:13:26.133676Z","shell.execute_reply.started":"2021-06-12T11:13:23.69809Z","shell.execute_reply":"2021-06-12T11:13:26.132749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:13:26.13543Z","iopub.execute_input":"2021-06-12T11:13:26.1357Z","iopub.status.idle":"2021-06-12T11:13:33.440848Z","shell.execute_reply.started":"2021-06-12T11:13:26.13567Z","shell.execute_reply":"2021-06-12T11:13:33.43991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertModel, BertTokenizerFast\ntokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\nfrom transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"onlplab/alephbert-base\", num_labels=3)\nmodel.save_pretrained(\"./initial_pretrained\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:13:33.442434Z","iopub.execute_input":"2021-06-12T11:13:33.442795Z","iopub.status.idle":"2021-06-12T11:13:56.798723Z","shell.execute_reply.started":"2021-06-12T11:13:33.44274Z","shell.execute_reply":"2021-06-12T11:13:56.797859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -latr ./initial_pretrained","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:13:56.800072Z","iopub.execute_input":"2021-06-12T11:13:56.800523Z","iopub.status.idle":"2021-06-12T11:13:57.460613Z","shell.execute_reply.started":"2021-06-12T11:13:56.80047Z","shell.execute_reply":"2021-06-12T11:13:57.459577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndataset = {\n            \"name\": \"Heb Poems\",\n            \"train_path\": \"../input/poetry/train.csv\",\n            \"dev_path\": \"../input/poetry/validation.csv\",\n            \"test_path\": \"../input/poetry/test.csv\",\n            'classes': ['0','1']\n          }\n\ndef read_data():\n    train = pd.read_csv(dataset['train_path'])\n    dev = pd.read_csv(dataset['dev_path'])\n    test = pd.read_csv(dataset['test_path'])\n    return train, dev, test\ntrain, dev, test = read_data()\ntrain_encodings = tokenizer(train[\"content\"].to_list(), truncation=True, padding=True)\ndev_encodings = tokenizer(dev[\"content\"].to_list(), truncation=True, padding=True)\ntest_encodings = tokenizer(test[\"content\"].to_list(), truncation=True, padding=True)\ntrain_labels=train[\"p_death_israel\"].to_list()\ndev_labels=dev[\"p_death_israel\"].to_list()\ntest_labels=test[\"p_death_israel\"].to_list()\n\nimport torch\n\nclass HebrewPoemsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = HebrewSentimentDataset(train_encodings, train_labels)\ndev_dataset = HebrewSentimentDataset(dev_encodings, dev_labels)\ntest_dataset = HebrewSentimentDataset(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:13:57.462372Z","iopub.execute_input":"2021-06-12T11:13:57.462732Z","iopub.status.idle":"2021-06-12T11:14:06.062109Z","shell.execute_reply.started":"2021-06-12T11:13:57.46268Z","shell.execute_reply":"2021-06-12T11:14:06.061113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:14:06.064364Z","iopub.execute_input":"2021-06-12T11:14:06.064631Z","iopub.status.idle":"2021-06-12T11:14:11.97343Z","shell.execute_reply.started":"2021-06-12T11:14:06.064604Z","shell.execute_reply":"2021-06-12T11:14:11.972448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer,TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=64,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10\n)\n\ntrainer = Trainer(\n    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=dev_dataset             # evaluation dataset\n)\n\ntrainer.train()\ntrainer.save_model(\"./alephbert_sentiment\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:14:11.975409Z","iopub.execute_input":"2021-06-12T11:14:11.975791Z","iopub.status.idle":"2021-06-12T11:31:23.03954Z","shell.execute_reply.started":"2021-06-12T11:14:11.975734Z","shell.execute_reply":"2021-06-12T11:31:23.038525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -latr ./alephbert_sentiment/","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:23.041208Z","iopub.execute_input":"2021-06-12T11:31:23.041578Z","iopub.status.idle":"2021-06-12T11:31:23.824756Z","shell.execute_reply.started":"2021-06-12T11:31:23.041539Z","shell.execute_reply":"2021-06-12T11:31:23.823883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:23.827874Z","iopub.execute_input":"2021-06-12T11:31:23.828128Z","iopub.status.idle":"2021-06-12T11:31:23.835032Z","shell.execute_reply.started":"2021-06-12T11:31:23.8281Z","shell.execute_reply":"2021-06-12T11:31:23.834213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_pred, _, _ = trainer.predict(test_dataset)\n\n# Preprocess raw predictions\ny_pred = np.argmax(raw_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:23.836196Z","iopub.execute_input":"2021-06-12T11:31:23.836542Z","iopub.status.idle":"2021-06-12T11:31:42.283572Z","shell.execute_reply.started":"2021-06-12T11:31:23.836506Z","shell.execute_reply":"2021-06-12T11:31:42.282741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:42.284965Z","iopub.execute_input":"2021-06-12T11:31:42.285325Z","iopub.status.idle":"2021-06-12T11:31:42.291825Z","shell.execute_reply.started":"2021-06-12T11:31:42.285288Z","shell.execute_reply":"2021-06-12T11:31:42.290907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset.labels","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:42.293164Z","iopub.execute_input":"2021-06-12T11:31:42.293713Z","iopub.status.idle":"2021-06-12T11:31:42.327666Z","shell.execute_reply.started":"2021-06-12T11:31:42.293674Z","shell.execute_reply":"2021-06-12T11:31:42.326645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_equals=0\nfor a,b in zip(test_dataset.labels, y_pred):\n    if a==b:\n        count_equals+=1\nprint(f\"accuracy={count_equals/len(y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T11:31:42.329562Z","iopub.execute_input":"2021-06-12T11:31:42.329855Z","iopub.status.idle":"2021-06-12T11:31:42.344533Z","shell.execute_reply.started":"2021-06-12T11:31:42.329828Z","shell.execute_reply":"2021-06-12T11:31:42.343199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}